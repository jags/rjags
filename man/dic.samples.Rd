\name{dic.samples}
\alias{dic.samples}
%- Also NEED an '\alias' for EACH other topic documented here.
\title{Generate penalized deviance samples}
\description{
  Function to extract random samples of the penalized deviance from
  a \code{jags} model.
}
\usage{
dic.samples(model, n.iter, thin = 1, type)
}
%- maybe also 'usage' for other objects documented here.
\arguments{
  \item{model}{a jags model object}
  \item{n.iter}{number of iterations to monitor}
  \item{thin}{thinning interval for monitors}
  \item{type}{type of penalty to use}
}
\details{

  The \code{dic.samples} function generates penalized deviance
  statistics.  The


  The two penalized deviance statistics generated by \code{dic.samples}
  are the deviance information criterion (DIC) and the penalized
  expected deviance.  These are chosen by giving the values ``pD'' and
  ``popt'' repectively as the \code{type} argument.

  DIC (Spiegelhalter et al 2002) is derived by adding the ``effective
  number of parameters'' (pD) to the expected deviance. The definition
  of pD used by \code{dic.samples} is the one proposed by Plummer (2002)
  and requires two or more parallel chains in the model.

  Plummer (2008) considers DIC as an approximation to the penalized
  plug-in deviance, which is used when only a point estimate of the
  parameters is of interest. The DIC approximation only holds
  asymptotically when the effective number of parameters is much smaller
  than the sample size.

  The penalized expected deviance penalizes complex models more severely
  than the plug-in deviance.  It has the advantage of not 

  The estimate of the penalty for optimism
  (popt) used by \code{dic.samples} uses importance weighting, and it
  may be numerically unstable.
  
  The deviance information
  criterion (DIC) is an approximation to the penalized plug-in
  deviance
  random variables in the model, runs the model for \code{n.iter}
  iterations and returns the monitored samples.
  
}
\value{
  An object of class ``dic''
  \item{deviance}{A list of \code{mcarray} objects, one for each
    observed stochastic node, containing samples of the deviance}
  \item{penalty}{A list of \code{mcarray} objects, one for each
    observed stochastic node, containing samples of the penalty
    function}
  \item{type}{A string identifying the type of penalty: ``pD'' or
    ``popt''}
}
\author{Martyn Plummer}
\references{
  Spiegelhalter, D., N. Best, B. Carlin, and A. van der Linde (2002),
  Bayesian measures of model complexity and fit (with discussion).
  \emph{Journal of the Royal Statistical Societey Series B}
  \bold{64}, 583â€“639.

  Plummer, M. (2002),
  Discussion of the paper by Spiegelhalter et al.
  \emph{Journal of the Royal Statistical Society Series B}
  \bold{64}, 620.

  Plummer, M. (2008)
  Penalized loss functions for Bayesian model comparison ,
  \emph{Biostatistics}
  doi: 10.1093/biostatistics/kxm049
}
\seealso{\code{\link{diffdic}}}
\keyword{models}
